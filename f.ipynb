{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ce1c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df, train, validate, test = wrangle_draft.wrangle_zillow()\n",
      "Files from wrangle: \n",
      "new_zillow_data \n",
      "get_zillow_data \n",
      "prep_zillow \n",
      "split_zillow_data \n",
      "wrangle_zillow\n",
      "df, train, validate, test = wrangle_final.wrangle_zillow()\n"
     ]
    }
   ],
   "source": [
    "# personally made imports\n",
    "import pandas as pd\n",
    "import env\n",
    "import wrangle_draft\n",
    "import wrangle_final\n",
    "#import explore_py\n",
    "\n",
    "# typical imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# modeling methods\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_and_continuous_vars(df, cat_col, cont_col):\n",
    "\n",
    "    for i, col in enumerate(cat_col):\n",
    "        plt.figure(figsize=(16, 3))\n",
    "        # i starts at 0, but plot nos should start at 1\n",
    "        plot_number = i + 1\n",
    "\n",
    "        l= len(cat_col)\n",
    "\n",
    "        plt.subplot(1,l,plot_number)\n",
    "\n",
    "        # Title with column name.\n",
    "        plt.title(col)\n",
    "        \n",
    "        sns.stripplot(x = df[col], y = df.tax_value)\n",
    "        #--------------------------------------------------------------\n",
    "        plt.figure(figsize=(16, 3))\n",
    "        # i starts at 0, but plot nos should start at 1\n",
    "        plot_number = i + 1\n",
    "\n",
    "        l= len(cat_col)\n",
    "\n",
    "        plt.subplot(1,l,plot_number)\n",
    "\n",
    "        # Title with column name.\n",
    "        plt.title(col)\n",
    "        \n",
    "        sns.boxplot(df[col], y = df.tax_value)\n",
    "        \n",
    "        #--------------------------------------------------------------\n",
    "        plt.figure(figsize=(16, 3))\n",
    "        # i starts at 0, but plot nos should start at 1\n",
    "        plot_number = i + 1\n",
    "\n",
    "        l= len(cat_col)\n",
    "\n",
    "        plt.subplot(1,l,plot_number)\n",
    "\n",
    "        # Title with column name.\n",
    "        plt.title(col)\n",
    "        \n",
    "        sns.barplot(df[col], y = df.tax_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a4220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Define function to scale all data based on the train subset\n",
    "def mms_scale_data(train, validate, test):\n",
    "    \n",
    "    mms_cols = ['sqft', 'yearbuilt']\n",
    "    \n",
    "    train_mms = train.copy()\n",
    "    validate_mms = validate.copy()\n",
    "    test_mms = test.copy()\n",
    "    \n",
    "    mms = MinMaxScaler()\n",
    "    \n",
    "    mms.fit(train[mms_cols])\n",
    "    \n",
    "    train_mms[mms_cols] = mms.transform(train[mms_cols])\n",
    "    validate_mms[mms_cols] = mms.transform(validate[mms_cols])\n",
    "    test_mms[mms_cols] = mms.transform(test[mms_cols])\n",
    "    \n",
    "    return train_mms, validate_mms, test_mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771f4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8061f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Define function to scale all data based on the train subset\n",
    "def ss_scale_data(train, validate, test):\n",
    "    \n",
    "    ss_cols = ['sqft', 'yearbuilt']\n",
    "    \n",
    "    train_ss = train.copy()\n",
    "    validate_ss = validate.copy()\n",
    "    test_ss = test.copy()\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    \n",
    "    ss.fit(train[ss_cols])\n",
    "    \n",
    "    train_ss[ss_cols] = ss.transform(train[ss_cols])\n",
    "    validate_ss[ss_cols] = ss.transform(validate[ss_cols])\n",
    "    test_ss[ss_cols] = ss.transform(test[ss_cols])\n",
    "    \n",
    "    return train_ss, validate_ss, test_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0544e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d660e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "\n",
    "    # create the model object\n",
    "    lm = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model ONLY to our training data.  \n",
    "\n",
    "    lm.fit(x_tr_data, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_predict = lm.predict(x_tr_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_predict)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_predict = lm.predict(x_val_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_predict)**(1/2)\n",
    "\n",
    "    return print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbfa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_lars(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "\n",
    "    # create the model object\n",
    "    lm = LassoLars(alpha=1.0)\n",
    "\n",
    "    # fit the model ONLY to our training data.  \n",
    "\n",
    "    lm.fit(x_tr_data, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_predict = lm.predict(x_tr_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_predict)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_predict = lm.predict(x_val_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_predict)**(1/2)\n",
    "\n",
    "    return print(\"RMSE for OLS using LassoLars\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e534cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glm(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "\n",
    "    # create the model object\n",
    "    lm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "    # fit the model ONLY to our training data.  \n",
    "\n",
    "    lm.fit(x_tr_data, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_predict = lm.predict(x_tr_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_predict)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_predict = lm.predict(x_val_data)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_predict)**(1/2)\n",
    "\n",
    "    return print(\"RMSE for OLS using GLM\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7dc737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c32178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_transform(x_tr_data, y_tr_data, x_val_data, y_val_data):\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled ONLY training gets fit, even for learning transformation!!!\n",
    "    x_tr_data_deg2 = pf.fit_transform(x_tr_data)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_val_data_deg2 = pf.transform(x_val_data)\n",
    "\n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data\n",
    "    lm2.fit(x_tr_data_deg2, y_tr_data)\n",
    "\n",
    "    # predict train\n",
    "    y_tr_data_deg2 = lm2.predict(x_tr_data_deg2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_tr_data, y_tr_data_deg2)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_val_data_deg2 = lm2.predict(x_val_data_deg2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_val_data, y_val_data_deg2)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train.round(2), \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a049c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f891b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862784ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab6013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eb775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace244b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
